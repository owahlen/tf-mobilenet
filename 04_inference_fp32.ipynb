{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inference with TRT FP32 model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TF-TRT FP32...\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Assets written to: saved_model/mobilenetv2_TFTRT_FP32/assets\n",
      "Done Converting to TF-TRT FP32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Assets written to: saved_model/mobilenetv2_TFTRT_FP32/assets\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_model/mobilenetv2')\n",
    "print('Converting to TF-TRT FP32...')\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                                               max_workspace_size_bytes=8000000000)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='saved_model/mobilenetv2',\n",
    "                                    conversion_params=conversion_params)\n",
    "\n",
    "def input_fn():\n",
    "    for i in range(50):\n",
    "        inp = tf.random.uniform((1, 160, 160, 3), minval=-1, maxval=1)\n",
    "        yield [inp]\n",
    "converter.convert()\n",
    "converter.build(input_fn=input_fn)\n",
    "converter.save(output_saved_model_dir='saved_model/mobilenetv2_TFTRT_FP32')\n",
    "print('Done Converting to TF-TRT FP32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# !saved_model_cli show --all --dir saved_model/mobilenetv2_TFTRT_FP32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature keys of optimized model:  ['serving_default']\n",
      "Outputs of serving_default:  {'predictions': TensorSpec(shape=<unknown>, dtype=tf.float32, name='predictions')}\n"
     ]
    }
   ],
   "source": [
    "optimized_model = tf.saved_model.load('saved_model/mobilenetv2_TFTRT_FP32', tags=[tag_constants.SERVING])\n",
    "signature_keys = list(optimized_model.signatures.keys())\n",
    "print('Signature keys of optimized model: ',signature_keys)\n",
    "infer = optimized_model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "print('Outputs of serving_default: ', infer.structured_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "ds, metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split='train',\n",
    "    with_info=True,\n",
    "    as_supervised=True)\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "decode_prediction = lambda x: 1 if x>=0 else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicteded 1000 images with accuracy of 99.90% with a rate of 401.58 images/s\n"
     ]
    }
   ],
   "source": [
    "n_predictions = 0\n",
    "n_correct_predictions = 0\n",
    "start_time = time.time()\n",
    "for image, label in ds.take(1000):\n",
    "    x = tf.cast(image, tf.float32)\n",
    "    x = (x/127.5)-1\n",
    "    x = tf.image.resize(x, (160,160))\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "\n",
    "    preds = infer(x)\n",
    "    n_predictions += 1\n",
    "    prediction = preds['predictions'][0,0] # only process first object at first batch index\n",
    "    decoded_pred = decode_prediction(prediction)\n",
    "    correct_prediction = label == decoded_pred\n",
    "    if correct_prediction:\n",
    "        n_correct_predictions += 1\n",
    "elapsed_time = time.time() - start_time\n",
    "accuracy = n_correct_predictions / n_predictions\n",
    "print('predicteded {} images with accuracy of {:.2f}% with a rate of {:.2f} images/s'.format(n_predictions, accuracy * 100, n_predictions/elapsed_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}