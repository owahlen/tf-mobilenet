{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inference with TRT FP16 model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TF-TRT FP16...\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Assets written to: saved_model/mobilenetv2_TFTRT_FP16/assets\n",
      "Done Converting to TF-TRT FP16\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_model/mobilenetv2')\n",
    "print('Converting to TF-TRT FP16...')\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "                                                               max_workspace_size_bytes=8000000000)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='saved_model/mobilenetv2',\n",
    "                                    conversion_params=conversion_params)\n",
    "\n",
    "def input_fn():\n",
    "    for i in range(50):\n",
    "        inp = tf.random.uniform((1, 160, 160, 3), minval=-1, maxval=1)\n",
    "        yield [inp]\n",
    "converter.convert()\n",
    "converter.build(input_fn=input_fn)\n",
    "converter.save(output_saved_model_dir='saved_model/mobilenetv2_TFTRT_FP16')\n",
    "print('Done Converting to TF-TRT FP16')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 18:22:10.471863: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['__saved_model_init_op']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['__saved_model_init_op'] tensor_info:\r\n",
      "        dtype: DT_INVALID\r\n",
      "        shape: unknown_rank\r\n",
      "        name: NoOp\r\n",
      "  Method name is: \r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['input'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 160, 160, 3)\r\n",
      "        name: serving_default_input:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['predictions'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: unknown_rank\r\n",
      "        name: PartitionedCall:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "2020-09-27 18:22:17.063523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n",
      "2020-09-27 18:22:17.066545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-09-27 18:22:17.066794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\n",
      "pciBusID: 0000:42:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n",
      "2020-09-27 18:22:17.066814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "2020-09-27 18:22:17.067984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n",
      "2020-09-27 18:22:17.069414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n",
      "2020-09-27 18:22:17.069632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n",
      "2020-09-27 18:22:17.070820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n",
      "2020-09-27 18:22:17.071480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n",
      "2020-09-27 18:22:17.071570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n",
      "2020-09-27 18:22:17.071684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-09-27 18:22:17.072018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-09-27 18:22:17.072230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n",
      "\r\n",
      "Defined Functions:\r\n",
      "  Function Name: '__call__'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          Input: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='Input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #2\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #3\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #4\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          Input: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='Input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "\r\n",
      "  Function Name: '_default_save_signature'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          Input: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='Input')\r\n",
      "\r\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #2\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #3\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          Input: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='Input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #4\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          Input: TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='Input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x7f11d922d440>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 202, in __del__\r\n",
      "    self._destroy_resource()\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n",
      "    result = self._call(*args, **kwds)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\r\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\r\n",
      "    *args, **kwds))\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n",
      "    graph_function = self._create_graph_function(args, kwargs)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\r\n",
      "    capture_by_value=self._capture_by_value),\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 237, in restored_function_body\r\n",
      "    return _call_concrete_function(function, inputs)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 74, in _call_concrete_function\r\n",
      "    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 106, in _call_flat\r\n",
      "    cancellation_manager)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1938, in _call_flat\r\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 579, in call\r\n",
      "    executor_type=executor_type)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py\", line 1192, in partitioned_call\r\n",
      "    f.add_to_graph(graph)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 495, in add_to_graph\r\n",
      "    g._add_function(self)\r\n",
      "  File \"/home/owahlen/anaconda3/envs/trt2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3345, in _add_function\r\n",
      "    gradient)\r\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null\r\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0_0._serialized_trt_resource_filename\r\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir saved_model/mobilenetv2_TFTRT_FP16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature keys of optimized model:  ['serving_default']\n",
      "Outputs of serving_default:  {'predictions': TensorSpec(shape=<unknown>, dtype=tf.float32, name='predictions')}\n"
     ]
    }
   ],
   "source": [
    "optimized_model = tf.saved_model.load('saved_model/mobilenetv2_TFTRT_FP16', tags=[tag_constants.SERVING])\n",
    "signature_keys = list(optimized_model.signatures.keys())\n",
    "print('Signature keys of optimized model: ',signature_keys)\n",
    "infer = optimized_model.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "print('Outputs of serving_default: ', infer.structured_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "ds, metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split='train',\n",
    "    with_info=True,\n",
    "    as_supervised=True)\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "decode_prediction = lambda x: 1 if x>=0 else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicteded 1000 images with accuracy of 99.90% with a rate of 490.71 images/s\n"
     ]
    }
   ],
   "source": [
    "n_predictions = 0\n",
    "n_correct_predictions = 0\n",
    "start_time = time.time()\n",
    "for image, label in ds.take(1000):\n",
    "    x = tf.cast(image, tf.float32)\n",
    "    x = (x/127.5)-1\n",
    "    x = tf.image.resize(x, (160,160))\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "\n",
    "    preds = infer(x)\n",
    "    n_predictions += 1\n",
    "    prediction = preds['predictions'][0,0] # only process first object at first batch index\n",
    "    decoded_pred = decode_prediction(prediction)\n",
    "    correct_prediction = label == decoded_pred\n",
    "    if correct_prediction:\n",
    "        n_correct_predictions += 1\n",
    "elapsed_time = time.time() - start_time\n",
    "accuracy = n_correct_predictions / n_predictions\n",
    "print('predicteded {} images with accuracy of {:.2f}% with a rate of {:.2f} images/s'.format(n_predictions, accuracy * 100, n_predictions/elapsed_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}